{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script used to change the docx file annotations to Pascal VOC XML type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import xml.etree.cElementTree as ET\n",
    "from PIL import Image\n",
    "\n",
    "ANNOTATIONS_DIR_PREFIX = r\"../Task/grape/labels/\"  ### Path to folder having both the images and the annotation docx files\n",
    "\n",
    "DESTINATION_DIR = \"..\\\\Task\\\\grape\\\\pascal_annotations\\\\\"  ##Path to folder where xml outputs are to be kept\n",
    "\n",
    "##Maping the name of the annotation\n",
    "CLASS_MAPPING = {\n",
    "    '0': 'Grape'\n",
    "}\n",
    "\n",
    "\n",
    "def create_root(file_prefix, width, height):\n",
    "    root = ET.Element(\"annotations\")\n",
    "    ET.SubElement(root, \"filename\").text = \"{}.jpg\".format(file_prefix)\n",
    "    ET.SubElement(root, \"folder\").text = \"images\"\n",
    "    size = ET.SubElement(root, \"size\")\n",
    "    ET.SubElement(size, \"width\").text = str(width)\n",
    "    ET.SubElement(size, \"height\").text = str(height)\n",
    "    ET.SubElement(size, \"depth\").text = \"3\"\n",
    "    return root\n",
    "\n",
    "\n",
    "def create_object_annotation(root, voc_labels):\n",
    "    for voc_label in voc_labels:\n",
    "        obj = ET.SubElement(root, \"object\")\n",
    "        ET.SubElement(obj, \"name\").text = voc_label[0]\n",
    "        ET.SubElement(obj, \"pose\").text = \"Unspecified\"\n",
    "        ET.SubElement(obj, \"truncated\").text = str(0)\n",
    "        ET.SubElement(obj, \"difficult\").text = str(0)\n",
    "        bbox = ET.SubElement(obj, \"bndbox\")\n",
    "        ET.SubElement(bbox, \"xmin\").text = str(voc_label[1])\n",
    "        ET.SubElement(bbox, \"ymin\").text = str(voc_label[2])\n",
    "        ET.SubElement(bbox, \"xmax\").text = str(voc_label[3])\n",
    "        ET.SubElement(bbox, \"ymax\").text = str(voc_label[4])\n",
    "    return root\n",
    "\n",
    "\n",
    "def create_file(file_prefix, width, height, voc_labels):\n",
    "    root = create_root(file_prefix, width, height)\n",
    "    root = create_object_annotation(root, voc_labels)\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(\"{}/{}.xml\".format(DESTINATION_DIR, file_prefix))\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    print(file_path)\n",
    "    file_prefix = file_path.split(\".docx\")[0]                      ## docx as our initial files are docx\n",
    "    image_file_name = \"{}.jpg\".format(file_prefix)\n",
    "    img = Image.open(\"{}/{}\".format(ANNOTATIONS_DIR_PREFIX, image_file_name))\n",
    "    w, h = img.size\n",
    "    print(\"File: \",file_path)\n",
    "    import docx\n",
    "#     doc = docx.Document(ANNOTATIONS_DIR_PREFIX+file_path)\n",
    "#     with docx.Document(ANNOTATIONS_DIR_PREFIX+file_path):\n",
    "    doc = docx.Document(ANNOTATIONS_DIR_PREFIX+file_path)\n",
    "    lines = [para.text for para in doc.paragraphs]\n",
    "    voc_labels = []\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            voc = []\n",
    "            line = line.strip()\n",
    "            print(line)\n",
    "            data = line.split()\n",
    "            print(data)\n",
    "            voc.append(CLASS_MAPPING.get(data[0]))\n",
    "            bbox_width = float(data[3]) * w\n",
    "            bbox_height = float(data[4]) * h\n",
    "            center_x = float(data[1]) * w\n",
    "            center_y = float(data[2]) * h\n",
    "            voc.append(center_x - (bbox_width / 2))\n",
    "            voc.append(center_y - (bbox_height / 2))\n",
    "            voc.append(center_x + (bbox_width / 2))\n",
    "            voc.append(center_y + (bbox_height / 2))\n",
    "            voc_labels.append(voc)\n",
    "        create_file(file_prefix, w, h, voc_labels)\n",
    "    print(\"Processing complete for file: {}\".format(file_path))\n",
    "\n",
    "\n",
    "def start():\n",
    "    if not os.path.exists(DESTINATION_DIR):\n",
    "        os.makedirs(DESTINATION_DIR)\n",
    "    for filename in os.listdir(ANNOTATIONS_DIR_PREFIX):\n",
    "        if filename.endswith('docx'):                           ##as from docx to xml\n",
    "            read_file(filename)\n",
    "        else:\n",
    "            print(\"Skipping file: {}\".format(filename))\n",
    "\n",
    "\n",
    "start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Imageai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "id": "qgqd1Xvvj0CQ",
    "outputId": "07b5fb8f-c08e-45b0-ec3f-a4b5a4c5e9e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageai\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/44/3d5d8ef572888025666eec284e85f9243faf06ca8c12085dcff1ca9754ed/imageai-2.1.6-py3-none-any.whl (160kB)\n",
      "\r",
      "\u001b[K     |██                              | 10kB 13.5MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 20kB 10.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 30kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 40kB 7.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 51kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 61kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 71kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 81kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 92kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 102kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 112kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 122kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 133kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 143kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 153kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 163kB 5.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imageai) (4.1.2.30)\n",
      "Collecting keras-resnet==0.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/76/d4/a35cbd07381139dda4db42c81b88c59254faac026109022727b45b31bcad/keras-resnet-0.2.0.tar.gz\n",
      "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (2.10.0)\n",
      "Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (from imageai) (2.4.3)\n",
      "Requirement already satisfied: pillow==7.0.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (7.0.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from imageai) (1.4.1)\n",
      "Collecting matplotlib==3.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/a6/8d7d06f6b69236a3c1818157875ceb1259ba0d9df4194f4fe138ffdc0f41/matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6MB)\n",
      "\u001b[K     |████████████████████████████████| 11.6MB 30.4MB/s \n",
      "\u001b[?25hCollecting numpy==1.19.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/b3/07864c89acb2a86df6f2e8c9bf091ec5916da58dd3ce3a633a51a02c115e/numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9MB 360kB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->imageai) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->imageai) (3.13)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2020.12.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.8.1)\n",
      "Building wheels for collected packages: keras-resnet\n",
      "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20486 sha256=44c934ffe142072b9fcbb90ab84ff6690a103163eb89f494486eeb9cd4c22148\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/09/a5/497a30fd9ad9964e98a1254d1e164bcd1b8a5eda36197ecb3c\n",
      "Successfully built keras-resnet\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-resnet, numpy, matplotlib, imageai\n",
      "  Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Found existing installation: matplotlib 3.2.2\n",
      "    Uninstalling matplotlib-3.2.2:\n",
      "      Successfully uninstalled matplotlib-3.2.2\n",
      "Successfully installed imageai-2.1.6 keras-resnet-0.2.0 matplotlib-3.3.2 numpy-1.19.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "matplotlib",
         "mpl_toolkits",
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install imageai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JV8ruBLpkKbD"
   },
   "source": [
    "Used the 300 images itself and didnt added any other cause was taking a lot of time to train and colab allows only 12 hours of GPU Runtime at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jYs7DcXPkT3v"
   },
   "outputs": [],
   "source": [
    "! mkdir ImageAI_OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OxhLX3lraEB",
    "outputId": "f4f4e7a9-58b9-4d76-d5b2-a08aef51d0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ImageAI_OCR\n"
     ]
    }
   ],
   "source": [
    "%cd ImageAI_OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Pretrained - Yolov3.h5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdIt5IErrdM5",
    "outputId": "d1a29ba0-3342-444a-bf8e-a7b69dee259c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-20 20:55:37--  https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5\n",
      "Resolving github.com (github.com)... 52.69.186.44\n",
      "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/125932201/12701d80-b2ab-11e9-9f56-c06e1dfbec05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210320T205537Z&X-Amz-Expires=300&X-Amz-Signature=33d454420beae8befa2f8020918b43f8e88dfb6792cc6bf092e312a87f5023ee&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dpretrained-yolov3.h5&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-03-20 20:55:37--  https://github-releases.githubusercontent.com/125932201/12701d80-b2ab-11e9-9f56-c06e1dfbec05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210320T205537Z&X-Amz-Expires=300&X-Amz-Signature=33d454420beae8befa2f8020918b43f8e88dfb6792cc6bf092e312a87f5023ee&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dpretrained-yolov3.h5&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.110.154, 185.199.109.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 248671664 (237M) [application/octet-stream]\n",
      "Saving to: ‘pretrained-yolov3.h5’\n",
      "\n",
      "pretrained-yolov3.h 100%[===================>] 237.15M  21.8MB/s    in 11s     \n",
      "\n",
      "2021-03-20 20:55:49 (21.4 MB/s) - ‘pretrained-yolov3.h5’ saved [248671664/248671664]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ugs8OojBrgJl"
   },
   "outputs": [],
   "source": [
    "##Importing modules from imageai\n",
    "from imageai.Detection.Custom import CustomObjectDetection         \n",
    "from imageai.Detection.Custom import DetectionModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ScA0mJa1rmpG",
    "outputId": "58a8ef6a-6885-4d2f-f0ed-734f7a3ff3cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor boxes for training images and annotation...\n",
      "Average IOU for 9 anchors: 0.78\n",
      "Anchor Boxes generated.\n",
      "Detection configuration saved in  /content/drive/MyDrive/rahul/grape/json/detection_config.json\n",
      "Evaluating over 50 samples taken from /content/drive/MyDrive/rahul/grape/validation\n",
      "Training over 250 samples  given at /content/drive/MyDrive/rahul/grape/train\n",
      "Training on: \t['Grape']\n",
      "Training with Batch Size:  8\n",
      "Number of Training Samples:  250\n",
      "Number of Validation Samples:  50\n",
      "Number of Experiments:  100\n",
      "Training with transfer learning from pretrained Model\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/100\n",
      "256/256 [==============================] - 368s 1s/step - loss: 144.0304 - yolo_layer_loss: 18.1149 - yolo_layer_1_loss: 33.4727 - yolo_layer_2_loss: 80.8627 - val_loss: 788.0274 - val_yolo_layer_loss: 184.8469 - val_yolo_layer_1_loss: 170.9331 - val_yolo_layer_2_loss: 420.6903\n",
      "Epoch 2/100\n",
      "256/256 [==============================] - 257s 993ms/step - loss: 88.1411 - yolo_layer_loss: 13.2442 - yolo_layer_1_loss: 23.0243 - yolo_layer_2_loss: 40.3380 - val_loss: 84.6709 - val_yolo_layer_loss: 14.7214 - val_yolo_layer_1_loss: 20.4634 - val_yolo_layer_2_loss: 38.0630\n",
      "Epoch 3/100\n",
      "256/256 [==============================] - 259s 997ms/step - loss: 76.9096 - yolo_layer_loss: 10.7900 - yolo_layer_1_loss: 19.5596 - yolo_layer_2_loss: 35.1845 - val_loss: 74.9509 - val_yolo_layer_loss: 13.8167 - val_yolo_layer_1_loss: 19.8631 - val_yolo_layer_2_loss: 30.0389\n",
      "Epoch 4/100\n",
      "256/256 [==============================] - 257s 993ms/step - loss: 73.0250 - yolo_layer_loss: 10.1031 - yolo_layer_1_loss: 18.5560 - yolo_layer_2_loss: 33.1865 - val_loss: 69.5713 - val_yolo_layer_loss: 12.1726 - val_yolo_layer_1_loss: 19.4399 - val_yolo_layer_2_loss: 26.9445\n",
      "Epoch 5/100\n",
      "256/256 [==============================] - 258s 996ms/step - loss: 68.5236 - yolo_layer_loss: 8.2779 - yolo_layer_1_loss: 15.7942 - yolo_layer_2_loss: 33.5002 - val_loss: 65.8242 - val_yolo_layer_loss: 10.5459 - val_yolo_layer_1_loss: 17.6281 - val_yolo_layer_2_loss: 26.8767\n",
      "Epoch 6/100\n",
      "256/256 [==============================] - 255s 983ms/step - loss: 67.3793 - yolo_layer_loss: 8.9569 - yolo_layer_1_loss: 16.5555 - yolo_layer_2_loss: 31.1481 - val_loss: 60.3652 - val_yolo_layer_loss: 7.7560 - val_yolo_layer_1_loss: 14.1000 - val_yolo_layer_2_loss: 27.9709\n",
      "Epoch 7/100\n",
      "256/256 [==============================] - 257s 992ms/step - loss: 64.6366 - yolo_layer_loss: 8.2728 - yolo_layer_1_loss: 15.5810 - yolo_layer_2_loss: 30.3032 - val_loss: 65.3582 - val_yolo_layer_loss: 12.1421 - val_yolo_layer_1_loss: 17.1929 - val_yolo_layer_2_loss: 25.7190\n",
      "Epoch 8/100\n",
      "256/256 [==============================] - 258s 995ms/step - loss: 62.6819 - yolo_layer_loss: 7.8678 - yolo_layer_1_loss: 14.7470 - yolo_layer_2_loss: 29.8188 - val_loss: 56.3322 - val_yolo_layer_loss: 7.4614 - val_yolo_layer_1_loss: 12.9447 - val_yolo_layer_2_loss: 25.8434\n",
      "Epoch 9/100\n",
      "256/256 [==============================] - 258s 995ms/step - loss: 61.6512 - yolo_layer_loss: 7.3988 - yolo_layer_1_loss: 14.3647 - yolo_layer_2_loss: 29.8597 - val_loss: 58.7877 - val_yolo_layer_loss: 8.5832 - val_yolo_layer_1_loss: 14.8076 - val_yolo_layer_2_loss: 25.5390\n",
      "Epoch 10/100\n",
      "256/256 [==============================] - 257s 992ms/step - loss: 61.0158 - yolo_layer_loss: 8.5859 - yolo_layer_1_loss: 15.1450 - yolo_layer_2_loss: 27.4766 - val_loss: 64.2037 - val_yolo_layer_loss: 10.0973 - val_yolo_layer_1_loss: 14.8122 - val_yolo_layer_2_loss: 29.6355\n",
      "Epoch 11/100\n",
      "256/256 [==============================] - 256s 990ms/step - loss: 58.4612 - yolo_layer_loss: 7.0216 - yolo_layer_1_loss: 13.3859 - yolo_layer_2_loss: 28.4460 - val_loss: 57.5295 - val_yolo_layer_loss: 8.5826 - val_yolo_layer_1_loss: 14.3796 - val_yolo_layer_2_loss: 25.1039\n",
      "Epoch 12/100\n",
      "256/256 [==============================] - 256s 990ms/step - loss: 57.0757 - yolo_layer_loss: 6.6040 - yolo_layer_1_loss: 13.5361 - yolo_layer_2_loss: 27.5208 - val_loss: 56.5387 - val_yolo_layer_loss: 8.7799 - val_yolo_layer_1_loss: 14.4623 - val_yolo_layer_2_loss: 24.0203\n",
      "Epoch 13/100\n",
      "256/256 [==============================] - 255s 986ms/step - loss: 56.7562 - yolo_layer_loss: 6.5812 - yolo_layer_1_loss: 12.8443 - yolo_layer_2_loss: 28.0998 - val_loss: 53.9343 - val_yolo_layer_loss: 7.3801 - val_yolo_layer_1_loss: 13.2586 - val_yolo_layer_2_loss: 24.1958\n",
      "Epoch 14/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 56.3644 - yolo_layer_loss: 6.9836 - yolo_layer_1_loss: 13.2326 - yolo_layer_2_loss: 27.0902 - val_loss: 55.4922 - val_yolo_layer_loss: 8.3791 - val_yolo_layer_1_loss: 14.0984 - val_yolo_layer_2_loss: 24.0806\n",
      "Epoch 15/100\n",
      "256/256 [==============================] - 257s 992ms/step - loss: 55.5554 - yolo_layer_loss: 6.6941 - yolo_layer_1_loss: 12.9393 - yolo_layer_2_loss: 27.0255 - val_loss: 53.9992 - val_yolo_layer_loss: 7.7771 - val_yolo_layer_1_loss: 13.3629 - val_yolo_layer_2_loss: 24.0739\n",
      "Epoch 16/100\n",
      "256/256 [==============================] - 258s 996ms/step - loss: 55.1673 - yolo_layer_loss: 6.7814 - yolo_layer_1_loss: 12.5948 - yolo_layer_2_loss: 27.0436 - val_loss: 54.3454 - val_yolo_layer_loss: 8.3011 - val_yolo_layer_1_loss: 14.3218 - val_yolo_layer_2_loss: 23.0817\n",
      "Epoch 17/100\n",
      "256/256 [==============================] - 257s 991ms/step - loss: 53.3055 - yolo_layer_loss: 6.7238 - yolo_layer_1_loss: 12.7947 - yolo_layer_2_loss: 25.1796 - val_loss: 58.2878 - val_yolo_layer_loss: 10.9338 - val_yolo_layer_1_loss: 14.7825 - val_yolo_layer_2_loss: 24.0632\n",
      "Epoch 18/100\n",
      "256/256 [==============================] - 256s 989ms/step - loss: 54.1943 - yolo_layer_loss: 7.0706 - yolo_layer_1_loss: 13.3243 - yolo_layer_2_loss: 25.3231 - val_loss: 55.1629 - val_yolo_layer_loss: 7.5280 - val_yolo_layer_1_loss: 14.9255 - val_yolo_layer_2_loss: 24.3269\n",
      "Epoch 19/100\n",
      "256/256 [==============================] - 256s 985ms/step - loss: 52.6810 - yolo_layer_loss: 6.5041 - yolo_layer_1_loss: 12.6085 - yolo_layer_2_loss: 25.2170 - val_loss: 52.2373 - val_yolo_layer_loss: 9.0982 - val_yolo_layer_1_loss: 13.8044 - val_yolo_layer_2_loss: 21.0680\n",
      "Epoch 20/100\n",
      "256/256 [==============================] - 256s 989ms/step - loss: 52.6338 - yolo_layer_loss: 6.8256 - yolo_layer_1_loss: 12.6034 - yolo_layer_2_loss: 24.9662 - val_loss: 51.6923 - val_yolo_layer_loss: 8.3601 - val_yolo_layer_1_loss: 14.0201 - val_yolo_layer_2_loss: 21.1578\n",
      "Epoch 21/100\n",
      "256/256 [==============================] - 256s 987ms/step - loss: 51.7887 - yolo_layer_loss: 6.4753 - yolo_layer_1_loss: 11.9968 - yolo_layer_2_loss: 25.1869 - val_loss: 58.5809 - val_yolo_layer_loss: 9.9176 - val_yolo_layer_1_loss: 15.8593 - val_yolo_layer_2_loss: 24.7472\n",
      "Epoch 22/100\n",
      "256/256 [==============================] - 252s 974ms/step - loss: 50.4032 - yolo_layer_loss: 6.1371 - yolo_layer_1_loss: 11.9278 - yolo_layer_2_loss: 24.3054 - val_loss: 50.5834 - val_yolo_layer_loss: 7.3071 - val_yolo_layer_1_loss: 12.7308 - val_yolo_layer_2_loss: 22.5871\n",
      "Epoch 23/100\n",
      "256/256 [==============================] - 255s 984ms/step - loss: 50.3797 - yolo_layer_loss: 5.9952 - yolo_layer_1_loss: 11.6964 - yolo_layer_2_loss: 24.7549 - val_loss: 52.8467 - val_yolo_layer_loss: 7.6505 - val_yolo_layer_1_loss: 14.0078 - val_yolo_layer_2_loss: 23.3229\n",
      "Epoch 24/100\n",
      "256/256 [==============================] - 255s 983ms/step - loss: 50.3314 - yolo_layer_loss: 6.3446 - yolo_layer_1_loss: 11.8532 - yolo_layer_2_loss: 24.2898 - val_loss: 58.7698 - val_yolo_layer_loss: 10.3489 - val_yolo_layer_1_loss: 15.4521 - val_yolo_layer_2_loss: 25.1901\n",
      "Epoch 25/100\n",
      "256/256 [==============================] - 254s 981ms/step - loss: 48.2988 - yolo_layer_loss: 5.5385 - yolo_layer_1_loss: 10.7083 - yolo_layer_2_loss: 24.2960 - val_loss: 51.0489 - val_yolo_layer_loss: 7.4641 - val_yolo_layer_1_loss: 13.2722 - val_yolo_layer_2_loss: 22.6187\n",
      "Epoch 26/100\n",
      "256/256 [==============================] - 254s 978ms/step - loss: 49.0750 - yolo_layer_loss: 6.2072 - yolo_layer_1_loss: 11.4710 - yolo_layer_2_loss: 23.7209 - val_loss: 53.0900 - val_yolo_layer_loss: 9.3345 - val_yolo_layer_1_loss: 14.0689 - val_yolo_layer_2_loss: 22.0668\n",
      "Epoch 27/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 48.2023 - yolo_layer_loss: 5.6741 - yolo_layer_1_loss: 11.1153 - yolo_layer_2_loss: 23.8127 - val_loss: 50.9832 - val_yolo_layer_loss: 8.1349 - val_yolo_layer_1_loss: 13.4892 - val_yolo_layer_2_loss: 21.8134\n",
      "Epoch 28/100\n",
      "256/256 [==============================] - 254s 979ms/step - loss: 47.8630 - yolo_layer_loss: 5.9413 - yolo_layer_1_loss: 11.4761 - yolo_layer_2_loss: 22.9172 - val_loss: 50.6188 - val_yolo_layer_loss: 6.6711 - val_yolo_layer_1_loss: 12.9150 - val_yolo_layer_2_loss: 23.5554\n",
      "Epoch 29/100\n",
      "256/256 [==============================] - 260s 1s/step - loss: 48.1409 - yolo_layer_loss: 6.3517 - yolo_layer_1_loss: 11.5180 - yolo_layer_2_loss: 22.8101 - val_loss: 50.8568 - val_yolo_layer_loss: 8.8778 - val_yolo_layer_1_loss: 12.9415 - val_yolo_layer_2_loss: 21.6216\n",
      "Epoch 30/100\n",
      "256/256 [==============================] - 257s 993ms/step - loss: 48.0803 - yolo_layer_loss: 6.5059 - yolo_layer_1_loss: 11.6208 - yolo_layer_2_loss: 22.5523 - val_loss: 48.1638 - val_yolo_layer_loss: 6.8833 - val_yolo_layer_1_loss: 12.4351 - val_yolo_layer_2_loss: 21.4877\n",
      "Epoch 31/100\n",
      "256/256 [==============================] - 254s 980ms/step - loss: 45.8247 - yolo_layer_loss: 5.5791 - yolo_layer_1_loss: 10.8716 - yolo_layer_2_loss: 22.0187 - val_loss: 49.1894 - val_yolo_layer_loss: 8.1465 - val_yolo_layer_1_loss: 13.4226 - val_yolo_layer_2_loss: 20.2730\n",
      "Epoch 32/100\n",
      "256/256 [==============================] - 258s 993ms/step - loss: 45.6457 - yolo_layer_loss: 6.3348 - yolo_layer_1_loss: 11.2542 - yolo_layer_2_loss: 20.7120 - val_loss: 48.1986 - val_yolo_layer_loss: 7.5031 - val_yolo_layer_1_loss: 12.6522 - val_yolo_layer_2_loss: 20.7059\n",
      "Epoch 33/100\n",
      "256/256 [==============================] - 255s 984ms/step - loss: 43.9225 - yolo_layer_loss: 4.7879 - yolo_layer_1_loss: 10.3030 - yolo_layer_2_loss: 21.4966 - val_loss: 48.0572 - val_yolo_layer_loss: 8.0082 - val_yolo_layer_1_loss: 13.2518 - val_yolo_layer_2_loss: 19.4696\n",
      "Epoch 34/100\n",
      "256/256 [==============================] - 255s 986ms/step - loss: 42.4516 - yolo_layer_loss: 4.4290 - yolo_layer_1_loss: 9.4165 - yolo_layer_2_loss: 21.2809 - val_loss: 46.9499 - val_yolo_layer_loss: 6.8433 - val_yolo_layer_1_loss: 11.5811 - val_yolo_layer_2_loss: 21.2073\n",
      "Epoch 35/100\n",
      "256/256 [==============================] - 256s 990ms/step - loss: 43.2748 - yolo_layer_loss: 4.8202 - yolo_layer_1_loss: 10.1879 - yolo_layer_2_loss: 20.9508 - val_loss: 47.4207 - val_yolo_layer_loss: 7.1859 - val_yolo_layer_1_loss: 11.9713 - val_yolo_layer_2_loss: 20.9545\n",
      "Epoch 36/100\n",
      "256/256 [==============================] - 258s 996ms/step - loss: 44.3906 - yolo_layer_loss: 5.5120 - yolo_layer_1_loss: 10.8463 - yolo_layer_2_loss: 20.7252 - val_loss: 47.3313 - val_yolo_layer_loss: 7.0448 - val_yolo_layer_1_loss: 12.2079 - val_yolo_layer_2_loss: 20.7779\n",
      "Epoch 37/100\n",
      "256/256 [==============================] - 256s 986ms/step - loss: 42.2895 - yolo_layer_loss: 4.6215 - yolo_layer_1_loss: 9.6550 - yolo_layer_2_loss: 20.7126 - val_loss: 46.0862 - val_yolo_layer_loss: 5.9869 - val_yolo_layer_1_loss: 11.2946 - val_yolo_layer_2_loss: 21.5049\n",
      "Epoch 38/100\n",
      "256/256 [==============================] - 256s 987ms/step - loss: 43.6865 - yolo_layer_loss: 5.2245 - yolo_layer_1_loss: 10.1835 - yolo_layer_2_loss: 20.9788 - val_loss: 47.3204 - val_yolo_layer_loss: 6.9102 - val_yolo_layer_1_loss: 12.0406 - val_yolo_layer_2_loss: 21.0706\n",
      "Epoch 39/100\n",
      "256/256 [==============================] - 255s 983ms/step - loss: 43.1570 - yolo_layer_loss: 5.1633 - yolo_layer_1_loss: 10.3307 - yolo_layer_2_loss: 20.3642 - val_loss: 46.2295 - val_yolo_layer_loss: 6.6167 - val_yolo_layer_1_loss: 11.6670 - val_yolo_layer_2_loss: 20.6477\n",
      "Epoch 40/100\n",
      "256/256 [==============================] - 259s 998ms/step - loss: 44.3645 - yolo_layer_loss: 5.9640 - yolo_layer_1_loss: 11.0636 - yolo_layer_2_loss: 20.0389 - val_loss: 45.9522 - val_yolo_layer_loss: 7.0329 - val_yolo_layer_1_loss: 11.3152 - val_yolo_layer_2_loss: 20.3061\n",
      "Epoch 41/100\n",
      "256/256 [==============================] - 256s 989ms/step - loss: 42.3497 - yolo_layer_loss: 4.5048 - yolo_layer_1_loss: 9.4396 - yolo_layer_2_loss: 21.1074 - val_loss: 49.2471 - val_yolo_layer_loss: 9.2529 - val_yolo_layer_1_loss: 13.3876 - val_yolo_layer_2_loss: 19.3088\n",
      "Epoch 42/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 41.9628 - yolo_layer_loss: 4.4070 - yolo_layer_1_loss: 9.3513 - yolo_layer_2_loss: 20.9065 - val_loss: 47.3284 - val_yolo_layer_loss: 7.6112 - val_yolo_layer_1_loss: 12.3299 - val_yolo_layer_2_loss: 20.0896\n",
      "Epoch 43/100\n",
      "256/256 [==============================] - 254s 980ms/step - loss: 42.2132 - yolo_layer_loss: 4.4108 - yolo_layer_1_loss: 9.4250 - yolo_layer_2_loss: 21.0796 - val_loss: 48.5297 - val_yolo_layer_loss: 7.8797 - val_yolo_layer_1_loss: 12.5751 - val_yolo_layer_2_loss: 20.7772\n",
      "Epoch 44/100\n",
      "256/256 [==============================] - 256s 990ms/step - loss: 43.7477 - yolo_layer_loss: 5.4936 - yolo_layer_1_loss: 10.5659 - yolo_layer_2_loss: 20.3905 - val_loss: 46.6085 - val_yolo_layer_loss: 7.0390 - val_yolo_layer_1_loss: 11.8145 - val_yolo_layer_2_loss: 20.4573\n",
      "Epoch 45/100\n",
      "256/256 [==============================] - 255s 983ms/step - loss: 43.2392 - yolo_layer_loss: 4.9572 - yolo_layer_1_loss: 10.0622 - yolo_layer_2_loss: 20.9221 - val_loss: 48.3319 - val_yolo_layer_loss: 7.7832 - val_yolo_layer_1_loss: 12.6891 - val_yolo_layer_2_loss: 20.5620\n",
      "Epoch 46/100\n",
      "256/256 [==============================] - 255s 986ms/step - loss: 42.8151 - yolo_layer_loss: 4.9660 - yolo_layer_1_loss: 9.9482 - yolo_layer_2_loss: 20.6033 - val_loss: 46.3667 - val_yolo_layer_loss: 6.4581 - val_yolo_layer_1_loss: 11.5219 - val_yolo_layer_2_loss: 21.0891\n",
      "Epoch 47/100\n",
      "256/256 [==============================] - 253s 978ms/step - loss: 42.1882 - yolo_layer_loss: 4.6303 - yolo_layer_1_loss: 9.5445 - yolo_layer_2_loss: 20.7157 - val_loss: 45.7818 - val_yolo_layer_loss: 6.1477 - val_yolo_layer_1_loss: 11.2557 - val_yolo_layer_2_loss: 21.0808\n",
      "Epoch 48/100\n",
      "256/256 [==============================] - 255s 984ms/step - loss: 42.1819 - yolo_layer_loss: 4.3391 - yolo_layer_1_loss: 9.4070 - yolo_layer_2_loss: 21.1381 - val_loss: 48.6325 - val_yolo_layer_loss: 7.9521 - val_yolo_layer_1_loss: 12.9885 - val_yolo_layer_2_loss: 20.3943\n",
      "Epoch 49/100\n",
      "256/256 [==============================] - 257s 993ms/step - loss: 42.1541 - yolo_layer_loss: 4.4910 - yolo_layer_1_loss: 9.7138 - yolo_layer_2_loss: 20.6517 - val_loss: 46.5377 - val_yolo_layer_loss: 6.3512 - val_yolo_layer_1_loss: 11.9211 - val_yolo_layer_2_loss: 20.9678\n",
      "Epoch 50/100\n",
      "256/256 [==============================] - 257s 992ms/step - loss: 42.8548 - yolo_layer_loss: 4.6905 - yolo_layer_1_loss: 9.9577 - yolo_layer_2_loss: 20.9089 - val_loss: 47.5785 - val_yolo_layer_loss: 7.3824 - val_yolo_layer_1_loss: 12.2253 - val_yolo_layer_2_loss: 20.6731\n",
      "Epoch 51/100\n",
      "256/256 [==============================] - 255s 985ms/step - loss: 43.2303 - yolo_layer_loss: 5.1492 - yolo_layer_1_loss: 10.1198 - yolo_layer_2_loss: 20.6637 - val_loss: 46.8389 - val_yolo_layer_loss: 6.6836 - val_yolo_layer_1_loss: 12.1122 - val_yolo_layer_2_loss: 20.7456\n",
      "Epoch 52/100\n",
      "256/256 [==============================] - 253s 979ms/step - loss: 41.9392 - yolo_layer_loss: 4.5993 - yolo_layer_1_loss: 9.3328 - yolo_layer_2_loss: 20.7095 - val_loss: 45.7650 - val_yolo_layer_loss: 6.0263 - val_yolo_layer_1_loss: 11.2072 - val_yolo_layer_2_loss: 21.2339\n",
      "Epoch 53/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 42.0552 - yolo_layer_loss: 4.2008 - yolo_layer_1_loss: 9.5352 - yolo_layer_2_loss: 21.0215 - val_loss: 48.4218 - val_yolo_layer_loss: 8.0541 - val_yolo_layer_1_loss: 12.5550 - val_yolo_layer_2_loss: 20.5150\n",
      "Epoch 54/100\n",
      "256/256 [==============================] - 255s 985ms/step - loss: 41.8328 - yolo_layer_loss: 4.4389 - yolo_layer_1_loss: 9.3192 - yolo_layer_2_loss: 20.7771 - val_loss: 46.5042 - val_yolo_layer_loss: 6.7586 - val_yolo_layer_1_loss: 12.2577 - val_yolo_layer_2_loss: 20.1903\n",
      "Epoch 55/100\n",
      "256/256 [==============================] - 255s 984ms/step - loss: 42.1108 - yolo_layer_loss: 4.6470 - yolo_layer_1_loss: 9.5334 - yolo_layer_2_loss: 20.6328 - val_loss: 46.1066 - val_yolo_layer_loss: 6.2114 - val_yolo_layer_1_loss: 11.7269 - val_yolo_layer_2_loss: 20.8706\n",
      "Epoch 56/100\n",
      "256/256 [==============================] - 255s 983ms/step - loss: 43.4161 - yolo_layer_loss: 5.4042 - yolo_layer_1_loss: 10.4177 - yolo_layer_2_loss: 20.2966 - val_loss: 47.4359 - val_yolo_layer_loss: 7.6837 - val_yolo_layer_1_loss: 12.5779 - val_yolo_layer_2_loss: 19.8767\n",
      "Epoch 57/100\n",
      "256/256 [==============================] - 256s 990ms/step - loss: 42.7186 - yolo_layer_loss: 4.8635 - yolo_layer_1_loss: 9.8872 - yolo_layer_2_loss: 20.6703 - val_loss: 46.9955 - val_yolo_layer_loss: 7.3173 - val_yolo_layer_1_loss: 12.1274 - val_yolo_layer_2_loss: 20.2532\n",
      "Epoch 58/100\n",
      "256/256 [==============================] - 257s 993ms/step - loss: 43.4111 - yolo_layer_loss: 5.1443 - yolo_layer_1_loss: 10.2203 - yolo_layer_2_loss: 20.7489 - val_loss: 47.3794 - val_yolo_layer_loss: 7.2317 - val_yolo_layer_1_loss: 12.2606 - val_yolo_layer_2_loss: 20.5895\n",
      "Epoch 59/100\n",
      "256/256 [==============================] - 256s 985ms/step - loss: 42.1117 - yolo_layer_loss: 4.6359 - yolo_layer_1_loss: 9.5932 - yolo_layer_2_loss: 20.5850 - val_loss: 47.5252 - val_yolo_layer_loss: 7.5648 - val_yolo_layer_1_loss: 12.4946 - val_yolo_layer_2_loss: 20.1681\n",
      "Epoch 60/100\n",
      "256/256 [==============================] - 254s 982ms/step - loss: 42.8688 - yolo_layer_loss: 5.1413 - yolo_layer_1_loss: 10.0068 - yolo_layer_2_loss: 20.4230 - val_loss: 46.8076 - val_yolo_layer_loss: 6.7647 - val_yolo_layer_1_loss: 11.7843 - val_yolo_layer_2_loss: 20.9610\n",
      "Epoch 61/100\n",
      "256/256 [==============================] - 255s 983ms/step - loss: 41.8823 - yolo_layer_loss: 4.2719 - yolo_layer_1_loss: 9.3872 - yolo_layer_2_loss: 20.9256 - val_loss: 47.2252 - val_yolo_layer_loss: 7.0949 - val_yolo_layer_1_loss: 12.2063 - val_yolo_layer_2_loss: 20.6263\n",
      "Epoch 62/100\n",
      "256/256 [==============================] - 257s 993ms/step - loss: 43.5781 - yolo_layer_loss: 5.2735 - yolo_layer_1_loss: 10.2792 - yolo_layer_2_loss: 20.7279 - val_loss: 46.5196 - val_yolo_layer_loss: 6.9115 - val_yolo_layer_1_loss: 11.8251 - val_yolo_layer_2_loss: 20.4853\n",
      "Epoch 63/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 43.4333 - yolo_layer_loss: 5.4106 - yolo_layer_1_loss: 10.6244 - yolo_layer_2_loss: 20.1007 - val_loss: 46.8627 - val_yolo_layer_loss: 6.9548 - val_yolo_layer_1_loss: 11.9427 - val_yolo_layer_2_loss: 20.6676\n",
      "Epoch 64/100\n",
      "256/256 [==============================] - 256s 987ms/step - loss: 42.2966 - yolo_layer_loss: 4.3990 - yolo_layer_1_loss: 9.4354 - yolo_layer_2_loss: 21.1646 - val_loss: 45.7174 - val_yolo_layer_loss: 6.2805 - val_yolo_layer_1_loss: 11.3166 - val_yolo_layer_2_loss: 20.8227\n",
      "Epoch 65/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 42.0076 - yolo_layer_loss: 4.3809 - yolo_layer_1_loss: 9.5444 - yolo_layer_2_loss: 20.7847 - val_loss: 47.9902 - val_yolo_layer_loss: 7.7778 - val_yolo_layer_1_loss: 12.6989 - val_yolo_layer_2_loss: 20.2159\n",
      "Epoch 66/100\n",
      "256/256 [==============================] - 256s 989ms/step - loss: 42.8606 - yolo_layer_loss: 5.0059 - yolo_layer_1_loss: 10.1131 - yolo_layer_2_loss: 20.4440 - val_loss: 46.8298 - val_yolo_layer_loss: 6.9801 - val_yolo_layer_1_loss: 12.0935 - val_yolo_layer_2_loss: 20.4586\n",
      "Epoch 67/100\n",
      "256/256 [==============================] - 256s 987ms/step - loss: 42.5413 - yolo_layer_loss: 4.6704 - yolo_layer_1_loss: 10.1409 - yolo_layer_2_loss: 20.4324 - val_loss: 47.3997 - val_yolo_layer_loss: 7.2215 - val_yolo_layer_1_loss: 12.0619 - val_yolo_layer_2_loss: 20.8187\n",
      "Epoch 68/100\n",
      "256/256 [==============================] - 257s 991ms/step - loss: 42.4897 - yolo_layer_loss: 4.7139 - yolo_layer_1_loss: 9.8920 - yolo_layer_2_loss: 20.5862 - val_loss: 48.2363 - val_yolo_layer_loss: 7.6579 - val_yolo_layer_1_loss: 13.0211 - val_yolo_layer_2_loss: 20.2597\n",
      "Epoch 69/100\n",
      "256/256 [==============================] - 256s 989ms/step - loss: 42.3945 - yolo_layer_loss: 4.7644 - yolo_layer_1_loss: 9.7986 - yolo_layer_2_loss: 20.5339 - val_loss: 46.5589 - val_yolo_layer_loss: 6.6441 - val_yolo_layer_1_loss: 11.9743 - val_yolo_layer_2_loss: 20.6429\n",
      "Epoch 70/100\n",
      "256/256 [==============================] - 256s 989ms/step - loss: 42.1449 - yolo_layer_loss: 4.3590 - yolo_layer_1_loss: 9.2882 - yolo_layer_2_loss: 21.2000 - val_loss: 47.4425 - val_yolo_layer_loss: 7.2689 - val_yolo_layer_1_loss: 12.0667 - val_yolo_layer_2_loss: 20.8093\n",
      "Epoch 71/100\n",
      "256/256 [==============================] - 262s 1s/step - loss: 43.0450 - yolo_layer_loss: 4.8145 - yolo_layer_1_loss: 10.0457 - yolo_layer_2_loss: 20.8872 - val_loss: 47.6956 - val_yolo_layer_loss: 7.7065 - val_yolo_layer_1_loss: 12.2667 - val_yolo_layer_2_loss: 20.4247\n",
      "Epoch 72/100\n",
      "256/256 [==============================] - 258s 997ms/step - loss: 42.4734 - yolo_layer_loss: 4.7490 - yolo_layer_1_loss: 9.6167 - yolo_layer_2_loss: 20.8100 - val_loss: 47.2210 - val_yolo_layer_loss: 6.8709 - val_yolo_layer_1_loss: 12.1052 - val_yolo_layer_2_loss: 20.9472\n",
      "Epoch 73/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 41.9600 - yolo_layer_loss: 4.0343 - yolo_layer_1_loss: 9.1608 - yolo_layer_2_loss: 21.4673 - val_loss: 45.8326 - val_yolo_layer_loss: 6.3857 - val_yolo_layer_1_loss: 11.1941 - val_yolo_layer_2_loss: 20.9552\n",
      "Epoch 74/100\n",
      "256/256 [==============================] - 259s 996ms/step - loss: 42.1835 - yolo_layer_loss: 4.2209 - yolo_layer_1_loss: 9.6628 - yolo_layer_2_loss: 21.0022 - val_loss: 47.8313 - val_yolo_layer_loss: 7.7751 - val_yolo_layer_1_loss: 12.7794 - val_yolo_layer_2_loss: 19.9792\n",
      "Epoch 75/100\n",
      "256/256 [==============================] - 255s 983ms/step - loss: 41.8625 - yolo_layer_loss: 4.2011 - yolo_layer_1_loss: 9.1365 - yolo_layer_2_loss: 21.2273 - val_loss: 47.0429 - val_yolo_layer_loss: 6.8233 - val_yolo_layer_1_loss: 12.0574 - val_yolo_layer_2_loss: 20.8646\n",
      "Epoch 76/100\n",
      "256/256 [==============================] - 258s 995ms/step - loss: 43.4776 - yolo_layer_loss: 5.4095 - yolo_layer_1_loss: 10.6483 - yolo_layer_2_loss: 20.1221 - val_loss: 48.1394 - val_yolo_layer_loss: 7.9420 - val_yolo_layer_1_loss: 12.5927 - val_yolo_layer_2_loss: 20.3071\n",
      "Epoch 77/100\n",
      "256/256 [==============================] - 257s 992ms/step - loss: 42.7594 - yolo_layer_loss: 4.5687 - yolo_layer_1_loss: 9.7869 - yolo_layer_2_loss: 21.1062 - val_loss: 46.8893 - val_yolo_layer_loss: 7.1102 - val_yolo_layer_1_loss: 11.7336 - val_yolo_layer_2_loss: 20.7479\n",
      "Epoch 78/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 41.6439 - yolo_layer_loss: 3.9864 - yolo_layer_1_loss: 9.1945 - yolo_layer_2_loss: 21.1653 - val_loss: 47.3586 - val_yolo_layer_loss: 7.3793 - val_yolo_layer_1_loss: 12.2895 - val_yolo_layer_2_loss: 20.3922\n",
      "Epoch 79/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 42.8069 - yolo_layer_loss: 4.5102 - yolo_layer_1_loss: 10.0124 - yolo_layer_2_loss: 20.9867 - val_loss: 46.8138 - val_yolo_layer_loss: 6.9815 - val_yolo_layer_1_loss: 12.0344 - val_yolo_layer_2_loss: 20.5003\n",
      "Epoch 80/100\n",
      "256/256 [==============================] - 256s 989ms/step - loss: 43.1457 - yolo_layer_loss: 5.2589 - yolo_layer_1_loss: 10.1880 - yolo_layer_2_loss: 20.4012 - val_loss: 45.5859 - val_yolo_layer_loss: 6.3377 - val_yolo_layer_1_loss: 11.0253 - val_yolo_layer_2_loss: 20.9253\n",
      "Epoch 81/100\n",
      "256/256 [==============================] - 257s 994ms/step - loss: 42.9861 - yolo_layer_loss: 5.1452 - yolo_layer_1_loss: 10.3092 - yolo_layer_2_loss: 20.2341 - val_loss: 48.1217 - val_yolo_layer_loss: 7.9093 - val_yolo_layer_1_loss: 12.9761 - val_yolo_layer_2_loss: 19.9386\n",
      "Epoch 82/100\n",
      "256/256 [==============================] - 258s 995ms/step - loss: 43.5661 - yolo_layer_loss: 5.6008 - yolo_layer_1_loss: 10.5564 - yolo_layer_2_loss: 20.1113 - val_loss: 47.8226 - val_yolo_layer_loss: 7.7680 - val_yolo_layer_1_loss: 12.2049 - val_yolo_layer_2_loss: 20.5520\n",
      "Epoch 83/100\n",
      "256/256 [==============================] - 256s 989ms/step - loss: 43.2153 - yolo_layer_loss: 5.1138 - yolo_layer_1_loss: 10.2172 - yolo_layer_2_loss: 20.5867 - val_loss: 46.6305 - val_yolo_layer_loss: 6.5892 - val_yolo_layer_1_loss: 11.4711 - val_yolo_layer_2_loss: 21.2725\n",
      "Epoch 84/100\n",
      "256/256 [==============================] - 257s 990ms/step - loss: 42.3026 - yolo_layer_loss: 4.6251 - yolo_layer_1_loss: 9.7251 - yolo_layer_2_loss: 20.6548 - val_loss: 46.0168 - val_yolo_layer_loss: 6.5680 - val_yolo_layer_1_loss: 11.5147 - val_yolo_layer_2_loss: 20.6364\n",
      "Epoch 85/100\n",
      "256/256 [==============================] - 255s 984ms/step - loss: 44.4140 - yolo_layer_loss: 5.7428 - yolo_layer_1_loss: 10.7096 - yolo_layer_2_loss: 20.6640 - val_loss: 46.4291 - val_yolo_layer_loss: 6.8083 - val_yolo_layer_1_loss: 11.7361 - val_yolo_layer_2_loss: 20.5871\n",
      "Epoch 86/100\n",
      "256/256 [==============================] - 255s 983ms/step - loss: 42.3033 - yolo_layer_loss: 4.6080 - yolo_layer_1_loss: 9.8332 - yolo_layer_2_loss: 20.5645 - val_loss: 48.4113 - val_yolo_layer_loss: 8.2746 - val_yolo_layer_1_loss: 13.2833 - val_yolo_layer_2_loss: 19.5558\n",
      "Epoch 87/100\n",
      "256/256 [==============================] - 256s 989ms/step - loss: 43.2185 - yolo_layer_loss: 5.4958 - yolo_layer_1_loss: 10.3575 - yolo_layer_2_loss: 20.0676 - val_loss: 47.0751 - val_yolo_layer_loss: 7.0840 - val_yolo_layer_1_loss: 11.9330 - val_yolo_layer_2_loss: 20.7605\n",
      "Epoch 88/100\n",
      "256/256 [==============================] - 258s 997ms/step - loss: 42.9735 - yolo_layer_loss: 5.2424 - yolo_layer_1_loss: 10.2645 - yolo_layer_2_loss: 20.1690 - val_loss: 47.2634 - val_yolo_layer_loss: 7.5566 - val_yolo_layer_1_loss: 12.1763 - val_yolo_layer_2_loss: 20.2329\n",
      "Epoch 89/100\n",
      "256/256 [==============================] - 258s 998ms/step - loss: 43.3922 - yolo_layer_loss: 5.1556 - yolo_layer_1_loss: 10.3837 - yolo_layer_2_loss: 20.5553 - val_loss: 47.7591 - val_yolo_layer_loss: 7.5101 - val_yolo_layer_1_loss: 12.6708 - val_yolo_layer_2_loss: 20.2805\n",
      "Epoch 90/100\n",
      "256/256 [==============================] - 259s 999ms/step - loss: 44.4473 - yolo_layer_loss: 5.9661 - yolo_layer_1_loss: 11.0336 - yolo_layer_2_loss: 20.1499 - val_loss: 46.6027 - val_yolo_layer_loss: 6.7630 - val_yolo_layer_1_loss: 11.6136 - val_yolo_layer_2_loss: 20.9285\n",
      "Epoch 91/100\n",
      "256/256 [==============================] - 258s 996ms/step - loss: 42.5275 - yolo_layer_loss: 4.6263 - yolo_layer_1_loss: 9.9700 - yolo_layer_2_loss: 20.6337 - val_loss: 48.0357 - val_yolo_layer_loss: 7.3711 - val_yolo_layer_1_loss: 12.5688 - val_yolo_layer_2_loss: 20.7981\n",
      "Epoch 92/100\n",
      "256/256 [==============================] - 262s 1s/step - loss: 43.7516 - yolo_layer_loss: 5.4223 - yolo_layer_1_loss: 10.6408 - yolo_layer_2_loss: 20.3909 - val_loss: 48.6403 - val_yolo_layer_loss: 7.7066 - val_yolo_layer_1_loss: 13.1537 - val_yolo_layer_2_loss: 20.4824\n",
      "Epoch 93/100\n",
      "256/256 [==============================] - 259s 997ms/step - loss: 43.4288 - yolo_layer_loss: 5.3158 - yolo_layer_1_loss: 10.3712 - yolo_layer_2_loss: 20.4441 - val_loss: 46.7476 - val_yolo_layer_loss: 6.4961 - val_yolo_layer_1_loss: 11.9246 - val_yolo_layer_2_loss: 21.0292\n",
      "Epoch 94/100\n",
      "256/256 [==============================] - 258s 998ms/step - loss: 42.8216 - yolo_layer_loss: 5.2003 - yolo_layer_1_loss: 10.1419 - yolo_layer_2_loss: 20.1819 - val_loss: 47.0497 - val_yolo_layer_loss: 7.1600 - val_yolo_layer_1_loss: 12.0843 - val_yolo_layer_2_loss: 20.5078\n",
      "Epoch 95/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 42.6049 - yolo_layer_loss: 4.4013 - yolo_layer_1_loss: 9.7894 - yolo_layer_2_loss: 21.1165 - val_loss: 47.1246 - val_yolo_layer_loss: 6.6069 - val_yolo_layer_1_loss: 11.7862 - val_yolo_layer_2_loss: 21.4339\n",
      "Epoch 96/100\n",
      "256/256 [==============================] - 256s 988ms/step - loss: 41.9276 - yolo_layer_loss: 4.2287 - yolo_layer_1_loss: 9.1930 - yolo_layer_2_loss: 21.2083 - val_loss: 48.5511 - val_yolo_layer_loss: 7.8850 - val_yolo_layer_1_loss: 13.2631 - val_yolo_layer_2_loss: 20.1054\n",
      "Epoch 97/100\n",
      "256/256 [==============================] - 257s 994ms/step - loss: 43.5424 - yolo_layer_loss: 5.1404 - yolo_layer_1_loss: 10.6005 - yolo_layer_2_loss: 20.5039 - val_loss: 47.1433 - val_yolo_layer_loss: 6.9789 - val_yolo_layer_1_loss: 12.2895 - val_yolo_layer_2_loss: 20.5773\n",
      "Epoch 98/100\n",
      "256/256 [==============================] - 257s 990ms/step - loss: 43.0671 - yolo_layer_loss: 5.0340 - yolo_layer_1_loss: 10.2560 - yolo_layer_2_loss: 20.4794 - val_loss: 48.2766 - val_yolo_layer_loss: 7.8029 - val_yolo_layer_1_loss: 12.6561 - val_yolo_layer_2_loss: 20.5201\n",
      "Epoch 99/100\n",
      "256/256 [==============================] - 254s 982ms/step - loss: 40.6980 - yolo_layer_loss: 3.4935 - yolo_layer_1_loss: 8.5788 - yolo_layer_2_loss: 21.3280 - val_loss: 46.3598 - val_yolo_layer_loss: 6.7930 - val_yolo_layer_1_loss: 11.5805 - val_yolo_layer_2_loss: 20.6886\n",
      "Epoch 100/100\n",
      "256/256 [==============================] - 257s 993ms/step - loss: 43.3074 - yolo_layer_loss: 5.3025 - yolo_layer_1_loss: 10.2877 - yolo_layer_2_loss: 20.4196 - val_loss: 48.2072 - val_yolo_layer_loss: 7.8720 - val_yolo_layer_1_loss: 13.0412 - val_yolo_layer_2_loss: 19.9964\n"
     ]
    }
   ],
   "source": [
    "##imported the DetectionModelTrainer class and created an instance\n",
    "trainer = DetectionModelTrainer()\n",
    "\n",
    "##sets the model type of the object detection training instance to the YOLOv3 model\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "\n",
    "##set the path to your dataset’s folder\n",
    "trainer.setDataDirectory(data_directory = '../grape')\n",
    "\n",
    "##set the properties for the training instances\n",
    "trainer.setTrainConfig(object_names_array = [\"Grape\"],batch_size=8, num_experiments=100, train_from_pretrained_model=\"./pretrained-yolov3.h5\")\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the mAP score of your saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxD4MwJBsVlz",
    "outputId": "d1a3b812-f8bf-431f-bd3b-98364f14b0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model evaluation....\n",
      "Evaluating over 50 samples taken from /content/drive/MyDrive/rahul/grape/validation\n",
      "Training over 250 samples  given at /content/drive/MyDrive/rahul/grape/train\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  /content/drive/MyDrive/rahul/grape/models/detection_model-ex-037--loss-0043.253.h5 \n",
      "\n",
      "Evaluation samples:  50\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "Grape: 0.7392\n",
      "mAP: 0.7392\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  /content/drive/MyDrive/rahul/grape/models/detection_model-ex-041--loss-0042.482.h5 \n",
      "\n",
      "Evaluation samples:  50\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "Grape: 0.7415\n",
      "mAP: 0.7415\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  /content/drive/MyDrive/rahul/grape/models/detection_model-ex-042--loss-0042.421.h5 \n",
      "\n",
      "Evaluation samples:  50\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "Grape: 0.7447\n",
      "mAP: 0.7447\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  /content/drive/MyDrive/rahul/grape/models/detection_model-ex-047--loss-0042.223.h5 \n",
      "\n",
      "Evaluation samples:  50\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "Grape: 0.7403\n",
      "mAP: 0.7403\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  /content/drive/MyDrive/rahul/grape/models/detection_model-ex-052--loss-0041.626.h5 \n",
      "\n",
      "Evaluation samples:  50\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "Grape: 0.7413\n",
      "mAP: 0.7413\n",
      "===============================\n",
      "[{'model_file': '/content/drive/MyDrive/rahul/grape/models/detection_model-ex-037--loss-0043.253.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Grape': 0.7392025995597882}, 'evaluation_samples': 50, 'map': 0.7392025995597882}, {'model_file': '/content/drive/MyDrive/rahul/grape/models/detection_model-ex-041--loss-0042.482.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Grape': 0.7414831123146788}, 'evaluation_samples': 50, 'map': 0.7414831123146788}, {'model_file': '/content/drive/MyDrive/rahul/grape/models/detection_model-ex-042--loss-0042.421.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Grape': 0.7447361764365835}, 'evaluation_samples': 50, 'map': 0.7447361764365835}, {'model_file': '/content/drive/MyDrive/rahul/grape/models/detection_model-ex-047--loss-0042.223.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Grape': 0.7402638658957645}, 'evaluation_samples': 50, 'map': 0.7402638658957645}, {'model_file': '/content/drive/MyDrive/rahul/grape/models/detection_model-ex-052--loss-0041.626.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'Grape': 0.7412654315853637}, 'evaluation_samples': 50, 'map': 0.7412654315853637}]\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory='../grape')\n",
    "\n",
    "## json_path :detection_config.json generated during the training\n",
    "## model_path :path to a single model or the folder containing your saved models\n",
    "metrics = trainer.evaluateModel(model_path=\"../grape/models\", json_path=\"../grape/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyR7GgA5-JpJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Grape.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
